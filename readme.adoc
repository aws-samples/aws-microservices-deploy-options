= Deploying Microservices on AWS Cloud
:toc:

This repo contains a simple application that consists of three microservices. The sample application uses three services:

. "`webapp`": Web application microservice uses "`greeting`" and "`name`"" microservice to generate a greeting for a person.
. "`greeting`": A microservice that returns a greeting.
. "`name`": A microservice that returns a person’s name based upon `{id}` in the URL.

Each application is deployed using different AWS Compute options. Each deployment model will highlight:

. Local dev, test and debug
. Deployment options
. Deployment pipeline
. Logging
. Monitoring

== Build and Test Services using Maven

Change to the "`services`" directory: `cd services`

. Greeting service in Terminal 1: `mvn -pl greeting wildfly-swarm:run`
.. Optionally test: `curl http://localhost:8081/resources/greeting`
. Name service in Terminal 2: `mvn -pl name wildfly-swarm:run`
.. Optionally test:
... `curl http://localhost:8082/resources/names`
... `curl http://localhost:8082/resources/names/1`
. Webapp service in Terminal 3: `mvn -pl webapp wildfly-swarm:run`
. Invoke the application in Terminal 4: `curl http://localhost:8080/`

== Build and Push Docker images

=== Create Docker image

`mvn -pl <service> package -Pdocker` where `<service>` is `greeting`, `name` or `webapp`

=== Docker image name

By default, the Docker image name is `arungupta/<service>`. Create the image in your repo as: `mvn -pl <service> package -Pdocker -Ddocker.repo=<repo>`

=== Push Docker images to registry

```
docker push <repo>/greeting
docker push <repo>/name
docker push <repo>/webapp
```

This is a workaround until https://github.com/aws-samples/aws-compute-options/issues/4 is fixed.

== Amazon ECS and AWS Fargate

This section will explain how to create Amazon ECS cluster. The three microservices will be deployed on this cluster using `Fargate` and `EC2` mode.

NOTE: AWS Fargate is only supported in `us-east-1` region at this time. The instructions will only work in that region.

=== Deployment: Create Cluster using AWS Console

This section will explain how to create an ECS cluster using AWS Console.

https://github.com/aws-samples/aws-compute-options/issues/48

=== Deployment: Create Cluster using AWS CLI

This section will explain how to create an ECS cluster using AWS CLI.

. Create an ECS cluster:
+
```
aws ecs create-cluster --cluster-name MyCluster
```
+
. Create AWS resources
.. Get default VPC:
+
```
aws ec2 describe-vpcs --query 'Vpcs[?IsDefault==`true`].VpcId'
```
+
.. Get the list of key pairs:
+
```
aws ec2 describe-key-pairs
```
+
.. Create a security group:
+
```
aws ec2 create-security-group \
  --group-name MySecurityGroup \
  --vpc-id <default-vpc-id> \
  --description "ECS cluster security group

```
+
.. Enable SSH and an ingress at port `80`:
+
```
aws ec2 authorize-security-group-ingress \
  --group-id sg-0184fa45c2fbbed2f \
  --protocol tcp \
  --port 22 \
  --cidr 0.0.0.0/0
aws ec2 authorize-security-group-ingress \
  --group-id sg-0184fa45c2fbbed2f \
  --protocol tcp \
  --port 80 \
  --cidr 0.0.0.0/0
```
+
.. Check if `ecsInstanceRole` already exists:
+
```
aws iam list-roles --query 'Roles[?RoleName==`ecsInstanceRole`]'
```
+
If the output is empty, this means that the role does not exist and needs to be created. Create the role:
+
```
aws iam create-role \
  --role-name ecsInstanceRole \
  --assume-role-policy-document file://ecs-assume-role-policy.json
aws iam put-role-policy \
  --role-name ecsInstanceRole \
  --policy-name MyPolicy \
  --policy-document file://ecs-instance-role-policy.json
```
+
. Launch an instance (work in progress):
+
```
aws ec2 run-instances \
  --image-id ami-05b5277d \
  --count 3 \
  --instance-type c4.large \
  --security-group-ids sg-0184fa45c2fbbed2f \
  --key-name arun-us-west2 
```
+
. 

https://github.com/aws-samples/aws-microservices-deploy-options/issues/101

=== Deployment: Create Cluster using CloudFormation

This section will explain how to create an ECS cluster using CloudFormation.

https://github.com/aws-samples/aws-microservices-deploy-options/issues/102

=== Deployment: Deploy Tasks and Service using AWS CLI

This section will explain how to deploy tasks and services in Fargate and EC2 mode using AWS CLI. Difference between the two deployment modes will be clearly highlighted.

https://github.com/aws-samples/aws-microservices-deploy-options/issues/103

=== Deployment: Deploy Tasks and Service using ECS CLI

This section will explain how to create an ECS cluster using a CloudFormation template. The tasks are then deployed using ECS CLI and Docker Compose definitions.

==== Pre-requisites

. Install https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_CLI.html[ECS CLI].
. Install - https://www.perl.org/get.html[Perl].

==== Deploy the application

. Run the CloudFormation template to create the AWS resources:
+
|===
|Region | Launch Template
| *N. Virginia* (us-east-1)
a| image::./images/deploy-to-aws.png[link=https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=aws-microservices-deploy-options-ecscli&templateURL=https://s3.amazonaws.com/aws-microservices-deploy-options/infra.yaml]
|===
+
. Run the follow command to capture the output from the CloudFormation template as key/value pairs in the file `ecs-cluster.props`. These will be used to setup environment variables which are used subseqently.

    aws cloudformation describe-stacks \
      --stack-name aws-microservices-deploy-options-ecscli \
      --query 'Stacks[0].Outputs' \
      --output=text | \
      perl -lpe 's/\s+/=/g' | \
      tee ecs-cluster.props

. Setup the environment variables using this file:

    set -o allexport
    source ecs-cluster.props
    set +o allexport

. Configure ECS CLI:

    ecs-cli configure --cluster $ECSCluster --region us-east-1 --default-launch-type FARGATE

. Create the task definition parameters for each of the service:
    
    ecs-params-create.sh greeting
    ecs-params-create.sh name
    ecs-params-create.sh webapp

. Start the `greeting` service up:

    ecs-cli compose --verbose \
      --file greeting-docker-compose.yaml \
      --task-role-arn $ECSRole \
      --ecs-params ecs-params_greeting.yaml \
      --project-name greeting \
      service up \
      --target-group-arn $GreetingTargetGroupArn \
      --container-name greeting-service \
      --container-port 8081

. Bring the `name` service up:

    ecs-cli compose --verbose \
      --file name-docker-compose.yaml \
      --task-role-arn $ECSRole \
      --ecs-params ecs-params_name.yaml  \
      --project-name name \
      service up \
      --target-group-arn $NameTargetGroupArn \
      --container-name name-service \
      --container-port 8082

. Bring the webapp service up:
+
    ecs-cli compose --verbose \
      --file webapp-docker-compose.yaml \
      --task-role-arn $ECSRole \
      --ecs-params ecs-params_webapp.yaml \
      --project-name webapp \
      service up \
      --target-group-arn $WebappTargetGroupArn \
      --container-name webapp-service \
      --container-port 8080
+
Docker Compose supports environment variable substitution. The `webapp-docker-compose.yaml` uses `$PrivateALBCName`  to refer to the private Application Load Balancer for `greeting` and `name` service.
+
. Check the `healthy` status of different services:

    aws elbv2 describe-target-health \
      --target-group-arn $GreetingTargetGroupArn \
      --query 'TargetHealthDescriptions[0].TargetHealth.State' \
      --output text
    aws elbv2 describe-target-health \
      --target-group-arn $NameTargetGroupArn \
      --query 'TargetHealthDescriptions[0].TargetHealth.State' \
      --output text
    aws elbv2 describe-target-health \
      --target-group-arn $WebappTargetGroupArn \
      --query 'TargetHealthDescriptions[0].TargetHealth.State' \
      --output text

. Once all the services are in `healthy` state, get a response from the `webapp` service:

  curl http://"$ALBPublicCNAME"
  Hello Sheldon

==== Tear down the resources

```
ecs-cli compose --verbose \
      --file greeting-docker-compose.yaml \
      --task-role-arn $ECSRole \
      --ecs-params ecs-params_greeting.yaml \
      --project-name greeting \
      service down
ecs-cli compose --verbose \
      --file name-docker-compose.yaml \
      --task-role-arn $ECSRole \
      --ecs-params ecs-params_name.yaml \
      --project-name name \
      service down
ecs-cli compose --verbose \
      --file webapp-docker-compose.yaml \
      --task-role-arn $ECSRole \
      --ecs-params ecs-params_webapp.yaml \
      --project-name webapp \
      service down
aws cloudformation delete-stack --region us-east-1 --stack-name aws-microservices-deploy-options-ecscli
```

=== Deployment: Create Cluster and Deploy Tasks using CloudFormation

==== Fargate

|===
|Region | Launch Template
| *N. Virginia* (us-east-1)
a| image::./images/deploy-to-aws.png[link=https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=aws-compute-options-fargate&templateURL=https://s3.amazonaws.com/compute-options-public/master.yaml]
|===

Retrieve the public endpoint to test your application deployment:

```
aws cloudformation \
    describe-stacks \
    --region us-east-1 \
    --stack-name aws-compute-options-fargate \
    --query "Stacks[].Outputs[?OutputKey=='PublicALBCNAME'.[OutputValue]]" \
    --output text
```

==== EC2 mode

|===
|Region | Launch Template
| *N. Virginia* (us-east-1)
a| image::./images/deploy-to-aws.png[link=https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=aws-compute-options-ecs&templateURL=https://s3.amazonaws.com/aws-compute-options-bucket/master.yaml]
|===

Retrieve the public endpoint to test your application deployment:

```
aws cloudformation \
    describe-stacks \
    --region us-east-1 \
    --stack-name aws-compute-options-ecs \
    --query 'Stacks[].Outputs[?OutputKey==`PublicALBCNAME`].[OutputValue]' \
    --output text
```

Use the command to test:

```
curl http://<public_endpoint>
```

=== Deployment Pipeline: AWS CodePipeline

https://github.com/aws-samples/aws-microservices-deploy-options/issues/104

=== Monitoring: AWS X-Ray

https://github.com/aws-samples/aws-microservices-deploy-options/issues/55

=== Monitoring: Prometheus and Grafana

https://github.com/aws-samples/aws-microservices-deploy-options/issues/78

== Kubernetes

=== Deployment: Standalone Manifests

Make sure `kubectl` CLI is installed and configured for the Kubernetes cluster.

. Apply the manifests: `kubectl apply -f apps/k8s/standalone/manifest.yml`
. Access the application: `curl http://$(kubectl get svc/webapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')`
. Delete the application: `kubectl delete -f apps/k8s/standalone/manifest.yml`

=== Deployment: Helm

Make sure `kubectl` CLI is installed and configured for the Kubernetes cluster. Also, make sure Helm is installed on that Kubernetes cluster.

. Install Helm CLI: `brew install kubernetes-helm`
. Install Helm in Kubernetes cluster: `helm init`
. Install Helm chart: `helm install --name myapp apps/k8s/helm/myapp`
. Access the application: `curl http://$(kubectl get svc/myapp-webapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')`
. Delete Helm chart: `helm delete --purge myapp`

=== Deployment: Ksonnet

Make sure `kubectl` CLI is installed and configured for the Kubernetes cluster.

. Install `ksonnet` from `homebrew` tap: `brew install ksonnet/tap/ks`
. Change into the ksonnet sub directory: `cd apps/k8s/ksonnet/myapp`
. Add the environment: `ks env add default`
. Deploy the manifests: `ks apply default`
. Access the application: `curl http://$(kubectl get svc/webapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')`
. Delete the application: `ks delete default`

=== Deployment: Docker Compose

https://github.com/aws-samples/aws-microservices-deploy-options/issues/62

=== Deployment: Kubepack

https://github.com/aws-samples/aws-microservices-deploy-options/issues/63

=== Deployment Pipeline: AWS Codepipeline

https://github.com/aws-samples/aws-microservices-deploy-options/issues/65

=== Deployment Pipeline: Jenkins

Create a deployment pipeline using http://jenkins-x.io/[Jenkins X].

. Install Jenkins X CLI:
+
```
brew tap jenkins-x/jx
brew install jx
```
+
. Create the Kubernetes cluster:
+
```
jx create cluster aws
```
+
This will create a Kubernetes cluster on AWS using kops. This cluster will have RBAC enabled. It will also have insecure registries enabled. These are needed by the pipeline to store Docker images.
+
. Clone the repo:
+
```
git clone https://github.com/arun-gupta/docker-kubernetes-hello-world
```
+
. Import the project in Jenkins X:
+
```
jx import 
```
+
This will generate `Dockerfile` and Helm charts, if they don't already exist. It also creates a `Jenkinsfile` with different build stages identified. Finally, it triggers a Jenkins build and deploy the application in a staging environment by default.
+
. View Jenkins console using `jx console`. Select the user, project and branch to see the deployment pipeline.
. Get the staging URL using `jx get apps` and view the output from the application in a browser window.
. Now change the message in displayed from `HelloHandler` and push to the GitHub repo. Make sure to change the corresponding test as well otherwise the pipeline will fail. Wait for the deployment to complete and then refresh the browser page to see the updated output.

=== Deployment Pipeline: Spinnaker

https://github.com/aws-samples/aws-microservices-deploy-options/issues/66

=== Monitoring: AWS X-Ray

. `arungupta/xray:us-west-2` Docker image is already available on Docker Hub. Optionally, you may build the image:
+
```
cd config/xray
docker build -t arungupta/xray:latest .
docker image push arungupta/xray:us-west-2
```
+
. Deploy the DaemonSet: `kubectl apply -f xray-daemonset.yaml`
. Deploy the application using Helm charts
. Access the application
. Open the https://us-west-2.console.aws.amazon.com/xray/home?region=us-west-2#/service-map[X-Ray console] and watch the service map and traces. This is tracked as https://github.com/aws-samples/aws-microservices-deploy-options/issues/60[#60].

=== Monitoring: Prometheus and Grafana

https://github.com/aws-samples/aws-microservices-deploy-options/issues/79

== AWS Lambda

=== Deployment: Package Lambda Functions

. `cd services`
. `mvn clean package -Plambda`

=== Deployment Pipeline: AWS CodePipeline

This section will explain how to deploy Lambda + API Gateway via CodePipeline.

. `cd apps/lambda`
. `aws cloudformation deploy --template-file pipeline.yaml --stack-name aws-compute-options-lambda-pipeline --capabilities CAPABILITY_IAM`
. `git remote add codecommit $(aws cloudformation describe-stacks --stack-name aws-compute-options-lambda-pipeline --query "Stacks[].Outputs[?OutputKey=='RepositoryHttpUrl'].OutputValue" --output text)`
. Setup your Git credential by following the https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-https-unixes.html[document]. This is required to push the code into the CodeCommit repo created in the CloudFormation stack. When the Git credential is setup, you can use the following command to push in the code and trigger the pieline to run.
+
```
git push codecommit master
```
+
. Get the URL to view the deployment pipeline:
+
```
aws cloudformation \
      describe-stacks \
      --stack-name aws-compute-options-lambda-pipeline \
      --query "Stacks[].Outputs[?OutputKey=='CodePipelineUrl'].[OutputValue]" \
      --output text
```
+
Deployment pipeline in AWS console looks like as shown:
+
image::images/lambda-pipeline.png[Lambda Pipeline, 350]

=== Deployment: Deploy SAM Manaully

. Create S3 bucket
+
```
aws s3api create-bucket \
  --bucket aws-compute-options \
  --region us-west-2 \
  --create-bucket-configuration LocationConstraint=us-west-2`
```
+
Make sure to change the bucket name.
+
. `cd apps/lambda`
. `sam package --template-file sam.yaml --s3-bucket YOUR-S3-BUCKET --output-template-file sam.transformed.yaml`
. `sam deploy --template-file sam.transformed.yaml --stack-name aws-compute-options-lambda --capabilities CAPABILITY_IAM`

=== Deployment: Test SAM Local

==== In Mac

. `sam local start-api --template sam.yaml --env-vars test/env-mac.json`
. Greeting endpoint: `curl http://127.0.0.1:3000/resources/greeting`
. Name endpoint:
.. `curl http://127.0.0.1:3000/resources/names`
.. `curl http://127.0.0.1:3000/resources/names/1`
. Webapp endpoint: `curl http://127.0.0.1:3000/`

==== In Windows

. `sam local start-api --template sam.yaml --env-vars test/env-win.json`
. Test the urls above in browser

=== Deployment: Test SAM on AWS

. Greeting endpoint:
+
```
curl `aws cloudformation \
  describe-stacks \
  --stack-name aws-compute-options-lambda \
  --query "Stacks[].Outputs[?OutputKey=='GreetingApiEndpoint'].[OutputValue]" \
  --output text`
```
+
. Name endpoint:
+
```
curl `aws cloudformation \
  describe-stacks \
  --stack-name aws-compute-options-lambda \
  --query "Stacks[].Outputs[?OutputKey=='NamesApiEndpoint'].[OutputValue]" \
  --output text`
```
+
. Webapp endpoint:
+
```
curl `aws cloudformation \
  describe-stacks \
  --stack-name aws-compute-options-lambda \
  --query "Stacks[].Outputs[?OutputKey=='WebappApiEndpoint'].[OutputValue]" \
  --output text`
```

=== Deployment: Composition using AWS Step Functions

https://github.com/aws-samples/aws-microservices-deploy-options/issues/76

=== Monitoring: AWS X-Ray

https://github.com/aws-samples/aws-microservices-deploy-options/issues/80

=== Deployment: Remove the stack

. `aws cloudformation delete-stack --stack-name aws-compute-options-lambda`

== Docker Swarm

=== Deployment

. `docker swarm init`
. `cd apps/docker`
. `docker stack deploy --compose-file docker-compose.yaml myapp`
. Access the application: `curl http://localhost:80`
.. Optionally test the endpoints:
... Greeting endpoint: `curl http://localhost:8081/resources/greeting`
... Name endpoint: `curl http://localhost:8082/resources/names/1`
. Remove the stack: `docker stack rm myapp`

=== Debug

. List stack:
+
```
$ docker stack ls
NAME                SERVICES
myapp               3
```
+
. List services in the stack:
+
```
$ docker stack services myapp
ID                  NAME                     MODE                REPLICAS            IMAGE                       PORTS
8hv33y3ry5la        myapp_greeting-service   replicated          1/1                 arungupta/greeting:latest   *:8081->8080/tcp
kyup1v84cv7q        myapp_name-service       replicated          1/1                 arungupta/name:latest       *:8082->8080/tcp
wcjhglfym28g        myapp_webapp-service     replicated          1/1                 arungupta/webapp:latest     *:80->8080/tcp
```
+
. List containers:
+
```
$ docker container ls -f name=myapp*
CONTAINER ID        IMAGE                       COMMAND                  CREATED             STATUS              PORTS                          NAMES
7cd2ec331b2a        arungupta/webapp:latest     "/deployments/run-ja…"   20 seconds ago      Up 20 seconds       8080/tcp, 8778/tcp, 9779/tcp   myapp_webapp-service.1.fvr9sae08ieu08lf8agfz2mwy
8436c6cc3110        arungupta/greeting:latest   "/deployments/run-ja…"   20 seconds ago      Up 18 seconds       8080/tcp, 8778/tcp, 9779/tcp   myapp_greeting-service.1.64idmwjlcvacniix6ll1egeoa
3a0a951f0a2d        arungupta/name:latest       "/deployments/run-ja…"   20 seconds ago      Up 20 seconds       8080/tcp, 8778/tcp, 9779/tcp   myapp_name-service.1.o7byxuzrc5vbfoyye8kuo19ws
```
+
. Get logs for all the containers in the `webapp` service:
+
```
$ docker service logs myapp_webapp-service
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | exec java -cp . -jar /deployments/webapp-swarm.jar
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:00,460 INFO  [org.wildfly.swarm] (main) WFSWARM0013: Installed fraction:                  Logging - STABLE          org.wildfly.swarm:logging:2018.2.0
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:00,514 INFO  [org.wildfly.swarm] (main) WFSWARM0013: Installed fraction:                  Elytron - STABLE          org.wildfly.swarm:elytron:2018.2.0
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:00,515 INFO  [org.wildfly.swarm] (main) WFSWARM0013: Installed fraction:                   JAX-RS - STABLE          org.wildfly.swarm:jaxrs:2018.2.0
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:00,516 INFO  [org.wildfly.swarm] (main) WFSWARM0013: Installed fraction:                 Undertow - STABLE          org.wildfly.swarm:undertow:2018.2.0
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:05,777 INFO  [org.jboss.msc] (main) JBoss MSC version 1.2.7.SP1
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:06,078 INFO  [org.jboss.as] (MSC service thread 1-8) WFLYSRV0049: WildFly Swarm 2018.2.0 (WildFly Core 3.0.8.Final) starting

. . .

org.jboss.as.server.deployment] (MSC service thread 1-5) WFLYSRV0027: Starting deployment of "webapp.war" (runtime-name: "webapp.war")
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:11,384 INFO  [org.wildfly.extension.undertow] (MSC service thread 1-5) WFLYUT0018: Host default-host starting
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:11,878 INFO  [org.jboss.resteasy.resteasy_jaxrs.i18n] (ServerService Thread Pool -- 10) RESTEASY002225: Deploying javax.ws.rs.core.Application: class org.wildfly.swarm.generated.WildFlySwarmDefaultJAXRSApplication
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:11,909 INFO  [org.wildfly.extension.undertow] (ServerService Thread Pool -- 10) WFLYUT0021: Registered web context: '/' for server 'default-server'
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:11,984 INFO  [org.jboss.as.server] (main) WFLYSRV0010: Deployed "webapp.war" (runtime-name : "webapp.war")
myapp_webapp-service.1.gb56vv5mw6u7@linuxkit-025000000001    | 2018-02-16 03:07:12,004 INFO  [org.wildfly.swarm] (main) WFSWARM99999: WildFly Swarm is Ready
```

== License

This library is licensed under the Amazon Software License.